{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c718293e-cb17-4cdf-a890-fca85e94580c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16268971-07ee-407c-ac9e-656a9dcbe4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from LOBOROBOT import LOBOROBOT # è½½å…¥æœºå™¨äººåº“\n",
    "from gpiozero import Button\n",
    "from gpiozero import LED\n",
    "import time \n",
    "import threading # çº¿ç¨‹W\n",
    "import ctypes\n",
    "import inspect\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef068a06-9a09-4fb6-b96f-0f7be8bec340",
   "metadata": {},
   "outputs": [],
   "source": [
    "#è¶…å£°æ¨¡å—ä¾èµ–\n",
    "from gpiozero import DistanceSensor\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf609502-7b0b-489d-96ef-3c9e7955be14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bgr8_to_jpeg(value, quality=75):\n",
    "    return bytes(cv2.imencode('.jpg', value)[1])\n",
    "\n",
    "def _async_raise(tid, exctype):\n",
    "    tid = ctypes.c_long(tid)\n",
    "    if not inspect.isclass(exctype):\n",
    "        exctype = type(exctype)\n",
    "    res = ctypes.pythonapi.PyThreadState_SetAsyncExc(tid, ctypes.py_object(exctype))\n",
    "    if res == 0:\n",
    "        raise ValueError(\"invalid thread id\")\n",
    "    elif res != 1:\n",
    "        ctypes.pythonapi.PyThreadState_SetAsyncExc(tid, None)\n",
    "        raise SystemError(\"PyThreadState_SetAsyncExc failed\")\n",
    "        \n",
    "def stop_thread(thread):\n",
    "    _async_raise(thread.ident, SystemExit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58718e04-e391-405f-b9bb-e94b855506e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æŒ‰é”®åŠLEDåˆå§‹åŒ–\n",
    "Btn  = Button(19,pull_up=True)   # æŒ‰é”®ç«¯å£\n",
    "Gpin = LED(5)\n",
    "Rpin = LED(6)\n",
    "\n",
    "#SensorRight = Button(16,pull_up=True)     # å³ä¾§çº¢å¤–é¿éšœä¼ æ„Ÿå™¨\n",
    "#SensorLeft  = Button(12,pull_up=True)    # å·¦ä¾§çº¢å¤–é¿éšœä¼ æ„Ÿå™¨\n",
    "\n",
    "#åˆå§‹åŒ–èˆµæœº\n",
    "clbrobot = LOBOROBOT()  # å®ä¾‹åŒ–æœºå™¨äººå¯¹è±¡\n",
    "clbrobot.t_stop(0)  # åœæ­¢\n",
    "\n",
    "# Configure min and max servo pulse lengths\n",
    "servo_min = 150  # Min pulse length out of 4096\n",
    "servo_max = 600  # Max pulse length out of 4096\n",
    "\n",
    "# é¢‘ç‡è®¾ç½®ä¸º50hzï¼Œé€‚ç”¨äºèˆµæœºç³»ç»Ÿã€‚\n",
    "clbrobot.set_servo_angle(10,85)  # åº•åº§èˆµæœº 90 \n",
    "clbrobot.set_servo_angle(9,25)  # é¡¶éƒ¨èˆµæœº 145(9,50)\n",
    "time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "823b06a6-c199-403d-b28e-117561c5fb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æŒ‰é”®æ ‡å¿—ä½\n",
    "keyflag = 0\n",
    "\n",
    "# æŒ‰é”®æ§åˆ¶å‡½æ•°\n",
    "def keysacn():\n",
    "    global keyflag\n",
    "    print('*****************************************') \n",
    "    print('* makerobo Button Pressed!*') \n",
    "    print('*****************************************')\n",
    "    Rpin.on()  # æ‰“å¼€çº¢è‰²LED\n",
    "    Gpin.off() # å…³é—­ç»¿è‰²LED\n",
    "    keyflag = 1   # æŒ‰é”®æ ‡å¿—ä½ç½®1\n",
    "\n",
    "def released():\n",
    "    print(\"button was released\")\n",
    "    Rpin.off()   # å…³é—­çº¢è‰²LED\n",
    "    Gpin.on()    # æ‰“å¼€ç»¿è‰²LED\n",
    "\n",
    "# æŒ‰é”®ä¸­æ–­å‡½æ•°+\n",
    "Btn.when_pressed = keysacn\n",
    "Btn.when_released = released"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85befb49-8ea1-48e0-a0d7-21b51538352b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è½½å…¥æ˜¾ç¤ºåº“\n",
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display\n",
    "import libcamera\n",
    "from picamera2 import Picamera2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0adb70e-773b-4159-a623-df42f74b7968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82c9c6c3567f4eb98de49ddbb0bab2ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg', height='120', width='180')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# äº‘å°æ‘„åƒå¤´å¯è§†åŒ–\n",
    "image = widgets.Image(format='jpeg', width=180, height=120)\n",
    "# image = widgets.Image(format='jpeg', width=1920, height=1080)\n",
    "display(image)\n",
    "\n",
    "def bgr8_to_jpeg(value, quality=75):\n",
    "    return bytes(cv2.imencode('.jpg', value)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79cdd3e8-52b9-4cb2-83e6-acd35118c327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # äº‘å°æ‘„åƒå¤´å¯è§†åŒ–\n",
    "# image_gray_0 = widgets.Image(format='jpeg', width=180, height=120)\n",
    "# # image = widgets.Image(format='jpeg', width=1920, height=1080)\n",
    "# display(image_gray_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6d4ffbe-187b-4688-844f-26ea1351828d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # äº‘å°æ‘„åƒå¤´å¯è§†åŒ–\n",
    "# image_blur_0 = widgets.Image(format='jpeg', width=180, height=120)\n",
    "# # image = widgets.Image(format='jpeg', width=1920, height=1080)\n",
    "# display(image_blur_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b42871de-c1d4-433a-a77c-4d0d8154b174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8368214d5d7b43e58b94311f1596816e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg', height='120', width='180')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# äº‘å°æ‘„åƒå¤´å¯è§†åŒ–\n",
    "image_thresh1_0 = widgets.Image(format='jpeg', width=180, height=120)\n",
    "# image = widgets.Image(format='jpeg', width=1920, height=1080)\n",
    "display(image_thresh1_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eaf6761f-17d4-4398-9f07-337ba899db27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # äº‘å°æ‘„åƒå¤´å¯è§†åŒ–\n",
    "# image_mask_0 = widgets.Image(format='jpeg', width=180, height=120)\n",
    "# # image = widgets.Image(format='jpeg', width=1920, height=1080)\n",
    "# display(image_mask_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "326335e1-0297-4719-89a7-a05ebb31f6b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03beaf7037844b01908ffe2176945572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg', height='720', width='1080')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# è¯†åˆ«æ‘„åƒå¤´å¯è§†åŒ–\n",
    "image_1 = widgets.Image(format='jpeg', width=1080, height=720)\n",
    "display(image_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22c1d934-da25-4f69-8346-bc6691c9fc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_camera():\n",
    "    # è·å–ç¬¬ä¸€ä¸ªæ‘„åƒå¤´\n",
    "    picamera_0 = Picamera2(camera_num=0)\n",
    "    config = picamera_0.create_preview_configuration(main={\"format\": 'RGB888', \"size\": (180, 120)},\n",
    "                                               raw={\"format\": \"SRGGB12\", \"size\": (720, 480)})\n",
    "    config[\"transform\"] = libcamera.Transform(hflip=1, vflip=1)\n",
    "    picamera_0.configure(config)\n",
    "    picamera_0.start()\n",
    "    \n",
    "    # è·å–ç¬¬äºŒä¸ªæ‘„åƒå¤´\n",
    "    picamera_1 = Picamera2(camera_num=1)\n",
    "    config = picamera_1.create_preview_configuration(main={\"format\": 'RGB888', \"size\": (1280, 720)},\n",
    "                                                   raw={\"format\": \"SRGGB12\", \"size\": (1280, 720)})\n",
    "    config[\"transform\"] = libcamera.Transform(hflip=0, vflip=1)\n",
    "    picamera_1.configure(config)\n",
    "    picamera_1.start()\n",
    "    return picamera_0,picamera_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e9a7e77-bcdd-4cf1-8498-828521d06818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.26.5, Python 3.11.2)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import gc\n",
    "import pygame,time,os\n",
    "\n",
    "# def Video_display_origin():\n",
    "#     picamera_0, picamera_1 = get_camera()\n",
    "#     no_line_counter = 0  # è¿ç»­ä¸¢çº¿å¸§è®¡æ•°å™¨\n",
    "#     frame_counter = 0  # æŠ½å¸§è®¡æ•°\n",
    "#     _already_played = False\n",
    "#     makerobo_sensor = DistanceSensor(echo=21, trigger=20, max_distance=3, threshold_distance=0.2) #è¶…å£°æ¨¡å—\n",
    "#     while True:\n",
    "#         frame_counter += 1\n",
    "#         dis = makerobo_sensor.distance * 100  # è¶…å£°æ¨¡å—æµ‹é‡è·ç¦»å€¼ï¼Œå¹¶æŠŠmå•ä½æ¢æˆcmå•ä½\n",
    "#         no_line_counter = line_track(picamera_0, no_line_counter, keyflag)\n",
    "#         if dis <=20 and not _already_played:   # ä¸Šå‡æ²¿è§¦å‘\n",
    "#             clbrobot.t_stop(3)\n",
    "#             _already_played = True             # æ ‡è®°â€œå·²æ’­â€\n",
    "#             results = yolo_detect(picamera_1, frame_counter)\n",
    "#             for result in results:\n",
    "#                 boxes = result.boxes  # Boxes å¯¹è±¡\n",
    "#                 names = result.names  # ç±»åˆ«å­—å…¸\n",
    "\n",
    "#             if boxes is not None:\n",
    "#                 for cls in boxes.cls:\n",
    "#                     print(\"è¯†åˆ«ç§ç±»ï¼š\", names[int(cls)])\n",
    "#                     if names[int(cls)] == \"ä»™äººçƒ\":\n",
    "#                         detect_result_read('results_read/ä»™äººæŒ.mp3')\n",
    "#                     elif names[int(cls)] == \"è–„è·å¶\":\n",
    "#                         detect_result_read('results_read/è–„è·å¶.mp3')\n",
    "#                     elif names[int(cls)] == \"é‡‘æç‰å¶\":\n",
    "#                         detect_result_read('results_read/é‡‘æç‰å¶.mp3')\n",
    "#                     elif names[int(cls)] == \"å‰åˆ©çº¢\":\n",
    "#                         detect_result_read('results_read/å‰ä¸½çº¢.mp3')\n",
    "#                     elif names[int(cls)] == \"ç»¿è\":\n",
    "#                         detect_result_read('results_read/ç»¿ç®©.mp3')\n",
    "#         elif dis >20:                       # ä¸€æ—¦å›åˆ° 0 å°±è§£é™¤é”å®š\n",
    "#             _already_played = False\n",
    "\n",
    "\n",
    "\n",
    "def Video_display():\n",
    "    picamera_0, picamera_1 = get_camera()\n",
    "    no_line_counter = 0  # è¿ç»­ä¸¢çº¿å¸§è®¡æ•°å™¨\n",
    "    frame_counter = 0    # æŠ½å¸§è®¡æ•°\n",
    "    _already_played = False\n",
    "    last_play_time = 0   # ä¸Šä¸€æ¬¡ detect_result_read çš„æ—¶é—´æˆ³\n",
    "    makerobo_sensor = DistanceSensor(echo=21, trigger=20, max_distance=3, threshold_distance=0.2) #è¶…å£°æ¨¡å—\n",
    "    while True:\n",
    "        dis = makerobo_sensor.distance * 100  # è¶…å£°æ¨¡å—æµ‹é‡è·ç¦»å€¼ï¼Œå¹¶æŠŠmå•ä½æ¢æˆcmå•ä½\n",
    "        frame_counter += 1\n",
    "        no_line_counter = line_track(picamera_0, no_line_counter, keyflag)\n",
    "\n",
    "        # --- æ£€æµ‹è§¦å‘ ---\n",
    "        if dis <=20 and not _already_played:\n",
    "            clbrobot.t_stop(3)\n",
    "            _already_played = True\n",
    "            last_play_time = time.time()  # è®°å½•å½“å‰æ—¶é—´\n",
    "            results = yolo_detect(picamera_1, frame_counter)\n",
    "\n",
    "            for result in results:\n",
    "                boxes = result.boxes  # Boxes å¯¹è±¡\n",
    "                names = result.names  # ç±»åˆ«å­—å…¸\n",
    "\n",
    "            if boxes is not None:\n",
    "                for cls in boxes.cls:\n",
    "                    name = names[int(cls)]\n",
    "                    print(\"è¯†åˆ«ç§ç±»ï¼š\", name)\n",
    "                    if name == \"ä»™äººçƒ\":\n",
    "                        detect_result_read('results_read/ä»™äººæŒ.mp3')\n",
    "                    elif name == \"è–„è·å¶\":\n",
    "                        detect_result_read('results_read/è–„è·å¶.mp3')\n",
    "                    elif name == \"é‡‘æç‰å¶\":\n",
    "                        detect_result_read('results_read/é‡‘æç‰å¶.mp3')\n",
    "                    elif name == \"å‰åˆ©çº¢\":\n",
    "                        detect_result_read('results_read/å‰ä¸½çº¢.mp3')\n",
    "                    elif name == \"ç»¿è\":\n",
    "                        detect_result_read('results_read/ç»¿ç®©.mp3')\n",
    "\n",
    "        # --- è§£é”æ¡ä»¶ ---\n",
    "        elif dis >20:\n",
    "            # ä»…åœ¨æ’­æ”¾å®Œæ¯•ä¸”è¶…è¿‡5ç§’åæ‰èƒ½é‡æ–°è§¦å‘\n",
    "            if _already_played and (time.time() - last_play_time >= 5):\n",
    "                _already_played = False\n",
    "\n",
    "            \n",
    "        \n",
    "\n",
    "def yolo_detect(picamera_1, frame_counter):\n",
    "    # Load a pretrained YOLO11n model\n",
    "    model = YOLO(\"best_ncnn_model\")\n",
    "    frame_1 = picamera_1.capture_array()\n",
    "    if frame_counter >= 1:\n",
    "        results = model.predict(frame_1)  # åªåœ¨è¿™é‡Œç”¨æ¨¡å‹æ¨ç†\n",
    "        #print(\"è¯†åˆ«ç»“æœä¸ºï¼š\", results)\n",
    "        '''\n",
    "        # è¾“å‡ºè¯†åˆ«ç»“æœ\n",
    "        for result in results:\n",
    "            boxes = result.boxes  # Boxes å¯¹è±¡\n",
    "            names = result.names  # ç±»åˆ«å­—å…¸\n",
    "\n",
    "            if boxes is not None:\n",
    "                for cls in boxes.cls:\n",
    "                    print(\"è¯†åˆ«ç§ç±»ï¼š\", names[int(cls)])\n",
    "        '''\n",
    "        # ç»˜åˆ¶æ£€æµ‹æ¡†\n",
    "        annotated_frame = results[0].plot()  # è¿”å›å¸¦æ¡†çš„å›¾åƒ\n",
    "        # æ˜¾ç¤ºæˆ–èµ‹å€¼ç»™ä½ åŸå…ˆçš„ widgets.Image\n",
    "        image_1.value = bgr8_to_jpeg(annotated_frame)\n",
    "        frame_counter = 0  # è®¡æ•°å™¨å½’é›¶\n",
    "    else:\n",
    "        image_1.value = bgr8_to_jpeg(frame_1)\n",
    "    return results\n",
    "\n",
    "def detect_result_read(mp3):\n",
    "    os.environ['SDL_AUDIODRIVER'] = 'alsa'\n",
    "    os.environ['AUDIODEV'] = 'hw:2,0'\n",
    "    pygame.mixer.init(frequency=44100, size=-16, channels=2, buffer=512)\n",
    "    pygame.mixer.music.load(mp3)\n",
    "    pygame.mixer.music.play()\n",
    "\n",
    "def line_track(picamera_0, no_line_counter, keyflag):\n",
    "    if keyflag == 1:\n",
    "        frame_0 = picamera_0.capture_array()\n",
    "        #frame_0 = cv2.flip(frame_0, 1)\n",
    "        #print(\"Height:\", frame_0.shape[0])\n",
    "        #print(\"Width :\", frame_0.shape[1])\n",
    "        #crop_img_0 = frame_0[0:180, 0:120]\n",
    "        crop_img_0 = frame_0\n",
    "        # gray_0 = cv2.cvtColor(crop_img_0, cv2.COLOR_BGR2GRAY)\n",
    "        # blur_0 = cv2.GaussianBlur(gray_0, (5,5), 0)\n",
    "        # ret_0, thresh1_0 = cv2.threshold(blur_0, 60, 255, cv2.THRESH_BINARY_INV)\n",
    "        hsv = cv2.cvtColor(crop_img_0, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        # æ£€æµ‹é»‘è‰²\n",
    "        lower_black = np.array([0, 0, 0])\n",
    "        upper_black = np.array([180, 255, 60])\n",
    "        thresh1_0 = cv2.inRange(hsv, lower_black, upper_black)\n",
    "        \n",
    "        mask_1 = cv2.erode(thresh1_0, None, iterations=2)\n",
    "        mask_0 = cv2.dilate(mask_1, None, iterations=2)\n",
    "        contours_0, hierarchy_0 = cv2.findContours(mask_0.copy(), 1, cv2.CHAIN_APPROX_NONE)\n",
    "        #print(\"len(contours_0): \",len(contours_0))\n",
    "        if len(contours_0) > 0:\n",
    "            no_line_counter = 0  # é‡ç½®ä¸¢çº¿è®¡æ•°\n",
    "            c = max(contours_0, key=cv2.contourArea)\n",
    "            M = cv2.moments(c)\n",
    "            if M['m00'] != 0:\n",
    "                cx = int(M['m10'] / M['m00'])\n",
    "                cy = int(M['m01'] / M['m00'])\n",
    "\n",
    "                cv2.line(crop_img_0, (cx, 0), (cx, 120), (0, 0, 255), 2)\n",
    "                cv2.line(crop_img_0, (120, 0), (120, 120), (0, 255, 255), 2)\n",
    "                cv2.line(crop_img_0, (70, 0), (70, 120), (0, 255, 255), 2)\n",
    "                \n",
    "                cv2.line(crop_img_0, (0, 60), (180, 60), (255, 0, 0), 2)\n",
    "                cv2.line(crop_img_0, (0, cy), (180, cy), (255, 255, 0), 2)\n",
    "                \n",
    "                cv2.drawContours(crop_img_0, contours_0, -1, (0, 255, 0), 1)\n",
    "                #print(\"cx:\",cx)\n",
    "                #if cx >= 115:\n",
    "                if cx >= 120:\n",
    "                    clbrobot.turnRight(25, 0)\n",
    "                    # clbrobot.turnRight(25, 0)\n",
    "                    #print(\"â¡ Turn Right!\")\n",
    "                elif cx < 120 and cx > 70:\n",
    "                    clbrobot.t_up(30, 0)\n",
    "                    #print(\"â¬† On Track!\")\n",
    "                elif cx <= 70:\n",
    "                    clbrobot.turnLeft(25, 0)\n",
    "                    # clbrobot.turnLeft(25, 0)\n",
    "                    #print(\"â¬… Turn Left!\")\n",
    "            else:\n",
    "                print(\"å¼‚å¸¸\")\n",
    "        else:\n",
    "            no_line_counter += 1\n",
    "            print(f\"âš  Line lost {no_line_counter} frame(s)\")\n",
    "            if no_line_counter >= 6:  # è¿ç»­6å¸§æœªæ£€æµ‹åˆ°çº¿æ‰åœè½¦\n",
    "                clbrobot.t_down(30,1.5)\n",
    "                no_line_counter = 0\n",
    "                print(\"ğŸ›‘ Stop due to no line detected!\")\n",
    "        #print(\"cx:\",cx,\"len(contours_0): \",len(contours_0))\n",
    "        #image.value = bgr8_to_jpeg(crop_img_0)\n",
    "        image.value = bgr8_to_jpeg(frame_0)\n",
    "        #image_gray_0.value = bgr8_to_jpeg(gray_0)\n",
    "        #image_blur_0.value = bgr8_to_jpeg(blur_0)\n",
    "        image_thresh1_0.value = bgr8_to_jpeg(thresh1_0)\n",
    "        #image_mask_1.value = bgr8_to_jpeg(mask_1)\n",
    "        #image_mask_0.value = bgr8_to_jpeg(mask_0)\n",
    "        return no_line_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c061e3a4-5744-4f2d-9511-74a01d6e3b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2508/3481196328.py:2: DeprecationWarning: setDaemon() is deprecated, set the daemon attribute instead\n",
      "  t.setDaemon(True)\n",
      "[0:17:34.490061718] [2572] \u001b[1;32m INFO \u001b[1;37mCamera \u001b[1;34mcamera_manager.cpp:325 \u001b[0mlibcamera v0.3.2+27-7330f29b\n",
      "[0:17:34.498911298] [2573] \u001b[1;32m INFO \u001b[1;37mRPI \u001b[1;34mpisp.cpp:695 \u001b[0mlibpisp version v1.0.7 28196ed6edcf 29-08-2024 (16:33:32)\n",
      "[0:17:34.508283911] [2573] \u001b[1;32m INFO \u001b[1;37mRPI \u001b[1;34mpisp.cpp:1154 \u001b[0mRegistered camera /base/axi/pcie@120000/rp1/i2c@80000/ov5647@36 to CFE device /dev/media1 and ISP device /dev/media0 using PiSP variant BCM2712_D0\n",
      "[0:17:34.624703926] [2573] \u001b[1;33m WARN \u001b[1;37mV4L2 \u001b[1;34mv4l2_pixelformat.cpp:346 \u001b[0mUnsupported V4L2 pixel format H264\n",
      "[0:17:34.629268821] [2572] \u001b[1;32m INFO \u001b[1;37mCamera \u001b[1;34mcamera.cpp:1197 \u001b[0mconfiguring streams: (0) 180x120-RGB888 (1) 1920x1080-SGRBG16\n",
      "[0:17:34.629378168] [2573] \u001b[1;32m INFO \u001b[1;37mRPI \u001b[1;34mpisp.cpp:1450 \u001b[0mSensor: /base/axi/pcie@120000/rp1/i2c@80000/ov5647@36 - Selected sensor format: 1920x1080-SGRBG10_1X10 - Selected CFE format: 1920x1080-GR16\n",
      "[0:17:34.751403372] [2572] \u001b[1;32m INFO \u001b[1;37mCamera \u001b[1;34mcamera.cpp:1197 \u001b[0mconfiguring streams: (0) 1280x720-MJPEG\n",
      "/usr/lib/python3/dist-packages/gpiozero/input_devices.py:852: PWMSoftwareFallback: For more accurate readings, use the pigpio pin factory.See https://gpiozero.readthedocs.io/en/stable/api_input.html#distancesensor-hc-sr04 for more info\n",
      "  warnings.warn(PWMSoftwareFallback(\n",
      "Exception in thread Thread-7 (Video_display):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3/dist-packages/gpiozero/devices.py\", line 584, in _check_open\n",
      "    super()._check_open()\n",
      "  File \"/usr/lib/python3/dist-packages/gpiozero/devices.py\", line 213, in _check_open\n",
      "    raise DeviceClosed(\n",
      "gpiozero.exc.DeviceClosed: DistanceSensor is closed or uninitialized\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 975, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_2508/69050548.py\", line 49, in Video_display\n",
      "  File \"/usr/lib/python3/dist-packages/gpiozero/input_devices.py\", line 905, in distance\n",
      "    return self.value * self._max_distance\n",
      "           ^^^^^^^^^^\n",
      "  File \"/usr/lib/python3/dist-packages/gpiozero/input_devices.py\", line 915, in value\n",
      "    return super().value\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3/dist-packages/gpiozero/input_devices.py\", line 322, in value\n",
      "    self._check_open()\n",
      "  File \"/usr/lib/python3/dist-packages/gpiozero/devices.py\", line 587, in _check_open\n",
      "    raise GPIODeviceClosed(str(e))\n",
      "gpiozero.exc.GPIODeviceClosed: DistanceSensor is closed or uninitialized\n"
     ]
    }
   ],
   "source": [
    "t = threading.Thread(target=Video_display)\n",
    "t.setDaemon(True)\n",
    "t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4dbc3f36-116c-4f0d-ba5a-600109c46464",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_thread(t)\n",
    "clbrobot.t_stop(0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177707ce-1c5f-46d5-8622-1d9e558692f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd719bf0-723f-4793-8c0b-f56c20f29c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657b93d6-d493-45c0-8dd9-07a6b9284b45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d91cb6c-a498-4411-afec-1980f23a63ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
